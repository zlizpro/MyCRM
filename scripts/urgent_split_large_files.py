#!/usr/bin/env python3
"""
ç´§æ€¥æ‹†åˆ†è¶…å¤§æ–‡ä»¶çš„è„šæœ¬

è¿™ä¸ªè„šæœ¬ä¼šè‡ªåŠ¨æ‹†åˆ†è¶…è¿‡200è¡Œçš„UIç»„ä»¶æ–‡ä»¶ï¼Œ
æŒ‰ç…§å•ä¸€èŒè´£åŸåˆ™å°†å¤§æ–‡ä»¶æ‹†åˆ†ä¸ºå¤šä¸ªå°æ–‡ä»¶ã€‚
"""

import ast
import os
import re
from pathlib import Path
from typing import Dict, List, Tuple, Optional
import shutil


class FileSplitter:
    """æ–‡ä»¶æ‹†åˆ†å™¨"""

    def __init__(self, max_lines: int = 200):
        self.max_lines = max_lines

    def analyze_file(self, file_path: Path) -> Dict:
        """åˆ†ææ–‡ä»¶ç»“æ„"""
        try:
            with open(file_path, "r", encoding="utf-8") as f:
                content = f.read()
                lines = content.split("\n")

            # è§£æAST
            tree = ast.parse(content)

            analysis = {
                "file_path": file_path,
                "total_lines": len(lines),
                "needs_split": len(lines) > self.max_lines,
                "imports": [],
                "classes": [],
                "functions": [],
                "constants": [],
            }

            # åˆ†æé¡¶çº§èŠ‚ç‚¹
            for node in ast.walk(tree):
                if isinstance(node, ast.Import):
                    for alias in node.names:
                        analysis["imports"].append(f"import {alias.name}")
                elif isinstance(node, ast.ImportFrom):
                    module = node.module or ""
                    names = [alias.name for alias in node.names]
                    analysis["imports"].append(
                        f"from {module} import {', '.join(names)}"
                    )
                elif isinstance(node, ast.ClassDef):
                    class_info = {
                        "name": node.name,
                        "lineno": node.lineno,
                        "end_lineno": getattr(node, "end_lineno", node.lineno),
                        "methods": [],
                    }

                    # åˆ†æç±»ä¸­çš„æ–¹æ³•
                    for item in node.body:
                        if isinstance(item, ast.FunctionDef):
                            class_info["methods"].append(
                                {
                                    "name": item.name,
                                    "lineno": item.lineno,
                                    "end_lineno": getattr(
                                        item, "end_lineno", item.lineno
                                    ),
                                }
                            )

                    analysis["classes"].append(class_info)
                elif isinstance(node, ast.FunctionDef) and node.col_offset == 0:
                    # é¡¶çº§å‡½æ•°
                    analysis["functions"].append(
                        {
                            "name": node.name,
                            "lineno": node.lineno,
                            "end_lineno": getattr(node, "end_lineno", node.lineno),
                        }
                    )
                elif isinstance(node, ast.Assign) and node.col_offset == 0:
                    # é¡¶çº§å¸¸é‡
                    for target in node.targets:
                        if isinstance(target, ast.Name):
                            analysis["constants"].append(
                                {"name": target.id, "lineno": node.lineno}
                            )

            return analysis

        except Exception as e:
            print(f"âŒ åˆ†ææ–‡ä»¶ {file_path} æ—¶å‡ºé”™: {e}")
            return None

    def create_split_plan(self, analysis: Dict) -> Optional[Dict]:
        """åˆ›å»ºæ‹†åˆ†è®¡åˆ’"""
        if not analysis or not analysis["needs_split"]:
            return None

        file_path = analysis["file_path"]
        file_name = file_path.stem

        # æ ¹æ®æ–‡ä»¶åç¡®å®šæ‹†åˆ†ç­–ç•¥
        if "form_panel" in file_name:
            return self._create_form_panel_split_plan(analysis)
        elif "data_table" in file_name:
            return self._create_data_table_split_plan(analysis)
        elif "search_widget" in file_name:
            return self._create_search_widget_split_plan(analysis)
        else:
            return self._create_generic_split_plan(analysis)

    def _create_form_panel_split_plan(self, analysis: Dict) -> Dict:
        """åˆ›å»ºè¡¨å•é¢æ¿æ‹†åˆ†è®¡åˆ’"""
        base_dir = analysis["file_path"].parent / "form"

        return {
            "strategy": "form_panel",
            "base_dir": base_dir,
            "files": {
                "form_panel.py": {
                    "description": "ä¸»è¡¨å•é¢æ¿ç±»",
                    "max_lines": 150,
                    "includes": ["FormPanelç±»çš„æ ¸å¿ƒæ–¹æ³•"],
                },
                "field_factory.py": {
                    "description": "å­—æ®µç»„ä»¶å·¥å‚",
                    "max_lines": 120,
                    "includes": ["å­—æ®µåˆ›å»ºç›¸å…³æ–¹æ³•"],
                },
                "form_validator.py": {
                    "description": "è¡¨å•éªŒè¯å™¨",
                    "max_lines": 100,
                    "includes": ["éªŒè¯ç›¸å…³æ–¹æ³•"],
                },
                "form_data_binder.py": {
                    "description": "æ•°æ®ç»‘å®šå™¨",
                    "max_lines": 80,
                    "includes": ["æ•°æ®ç»‘å®šç›¸å…³æ–¹æ³•"],
                },
                "form_layout_manager.py": {
                    "description": "å¸ƒå±€ç®¡ç†å™¨",
                    "max_lines": 90,
                    "includes": ["å¸ƒå±€ç›¸å…³æ–¹æ³•"],
                },
                "form_styles.py": {
                    "description": "æ ·å¼å®šä¹‰",
                    "max_lines": 60,
                    "includes": ["æ ·å¼å¸¸é‡å’Œæ–¹æ³•"],
                },
            },
        }

    def _create_data_table_split_plan(self, analysis: Dict) -> Dict:
        """åˆ›å»ºæ•°æ®è¡¨æ ¼æ‹†åˆ†è®¡åˆ’"""
        base_dir = analysis["file_path"].parent / "table"

        return {
            "strategy": "data_table",
            "base_dir": base_dir,
            "files": {
                "data_table.py": {
                    "description": "ä¸»è¡¨æ ¼ç±»",
                    "max_lines": 180,
                    "includes": ["DataTableç±»çš„æ ¸å¿ƒæ–¹æ³•"],
                },
                "table_data_manager.py": {
                    "description": "æ•°æ®ç®¡ç†å™¨",
                    "max_lines": 150,
                    "includes": ["æ•°æ®ç®¡ç†ç›¸å…³æ–¹æ³•"],
                },
                "table_filter_manager.py": {
                    "description": "ç­›é€‰ç®¡ç†å™¨",
                    "max_lines": 120,
                    "includes": ["ç­›é€‰ç›¸å…³æ–¹æ³•"],
                },
                "table_pagination_manager.py": {
                    "description": "åˆ†é¡µç®¡ç†å™¨",
                    "max_lines": 100,
                    "includes": ["åˆ†é¡µç›¸å…³æ–¹æ³•"],
                },
                "table_export_manager.py": {
                    "description": "å¯¼å‡ºç®¡ç†å™¨",
                    "max_lines": 80,
                    "includes": ["å¯¼å‡ºç›¸å…³æ–¹æ³•"],
                },
            },
        }

    def _create_search_widget_split_plan(self, analysis: Dict) -> Dict:
        """åˆ›å»ºæœç´¢ç»„ä»¶æ‹†åˆ†è®¡åˆ’"""
        base_dir = analysis["file_path"].parent / "search"

        return {
            "strategy": "search_widget",
            "base_dir": base_dir,
            "files": {
                "search_widget.py": {
                    "description": "ä¸»æœç´¢ç»„ä»¶",
                    "max_lines": 150,
                    "includes": ["SearchWidgetç±»çš„æ ¸å¿ƒæ–¹æ³•"],
                },
                "search_filter_manager.py": {
                    "description": "ç­›é€‰ç®¡ç†å™¨",
                    "max_lines": 120,
                    "includes": ["ç­›é€‰ç›¸å…³æ–¹æ³•"],
                },
                "search_history_manager.py": {
                    "description": "æœç´¢å†å²ç®¡ç†å™¨",
                    "max_lines": 100,
                    "includes": ["å†å²è®°å½•ç›¸å…³æ–¹æ³•"],
                },
                "search_config.py": {
                    "description": "æœç´¢é…ç½®",
                    "max_lines": 80,
                    "includes": ["é…ç½®ç›¸å…³ç±»å’Œå¸¸é‡"],
                },
            },
        }

    def _create_generic_split_plan(self, analysis: Dict) -> Dict:
        """åˆ›å»ºé€šç”¨æ‹†åˆ†è®¡åˆ’"""
        file_name = analysis["file_path"].stem
        base_dir = analysis["file_path"].parent / file_name.replace("_", "")

        return {
            "strategy": "generic",
            "base_dir": base_dir,
            "files": {
                f"{file_name}.py": {
                    "description": "ä¸»ç±»æ–‡ä»¶",
                    "max_lines": 150,
                    "includes": ["ä¸»è¦ç±»å®šä¹‰"],
                },
                f"{file_name}_manager.py": {
                    "description": "ç®¡ç†å™¨ç±»",
                    "max_lines": 120,
                    "includes": ["ç®¡ç†ç›¸å…³æ–¹æ³•"],
                },
                f"{file_name}_utils.py": {
                    "description": "å·¥å…·å‡½æ•°",
                    "max_lines": 100,
                    "includes": ["å·¥å…·å‡½æ•°å’Œå¸¸é‡"],
                },
            },
        }

    def execute_split_plan(self, analysis: Dict, split_plan: Dict) -> bool:
        """æ‰§è¡Œæ‹†åˆ†è®¡åˆ’"""
        try:
            print(
                f"ğŸ“‚ å¼€å§‹æ‹†åˆ† {analysis['file_path'].name} ({analysis['total_lines']}è¡Œ)"
            )

            # åˆ›å»ºç›®æ ‡ç›®å½•
            base_dir = split_plan["base_dir"]
            base_dir.mkdir(parents=True, exist_ok=True)

            # åˆ›å»º__init__.py
            init_file = base_dir / "__init__.py"
            with open(init_file, "w", encoding="utf-8") as f:
                f.write('"""æ‹†åˆ†åçš„æ¨¡å—åŒ…"""\n')

            # å¤‡ä»½åŸæ–‡ä»¶
            backup_path = analysis["file_path"].with_suffix(".py.backup")
            shutil.copy2(analysis["file_path"], backup_path)
            print(f"ğŸ“‹ å·²å¤‡ä»½åŸæ–‡ä»¶åˆ°: {backup_path}")

            # è¯»å–åŸæ–‡ä»¶å†…å®¹
            with open(analysis["file_path"], "r", encoding="utf-8") as f:
                original_content = f.read()

            # åˆ›å»ºæ‹†åˆ†åçš„æ–‡ä»¶ï¼ˆæš‚æ—¶åªåˆ›å»ºå ä½ç¬¦ï¼‰
            for file_name, file_info in split_plan["files"].items():
                target_file = base_dir / file_name

                with open(target_file, "w", encoding="utf-8") as f:
                    f.write(f'"""\n{file_info["description"]}\n\n')
                    f.write(f"ä» {analysis['file_path'].name} æ‹†åˆ†è€Œæ¥\n")
                    f.write(f"æœ€å¤§è¡Œæ•°é™åˆ¶: {file_info['max_lines']}è¡Œ\n")
                    f.write(f"åŒ…å«å†…å®¹: {', '.join(file_info['includes'])}\n")
                    f.write('"""\n\n')
                    f.write("# TODO: ä»åŸæ–‡ä»¶ä¸­ç§»åŠ¨ç›¸å…³ä»£ç åˆ°è¿™é‡Œ\n")
                    f.write("# ç¡®ä¿æ¯ä¸ªæ–‡ä»¶ä¸è¶…è¿‡æŒ‡å®šçš„è¡Œæ•°é™åˆ¶\n")
                    f.write("# ä½¿ç”¨transfunctionsæ›¿æ¢é‡å¤å®ç°\n\n")

                print(f"ğŸ“„ åˆ›å»ºæ–‡ä»¶: {target_file} (æœ€å¤§{file_info['max_lines']}è¡Œ)")

            # åˆ›å»ºé‡æ„æŒ‡å—
            guide_file = base_dir / "REFACTOR_GUIDE.md"
            with open(guide_file, "w", encoding="utf-8") as f:
                f.write(f"# {analysis['file_path'].name} é‡æ„æŒ‡å—\n\n")
                f.write(f"## åŸæ–‡ä»¶ä¿¡æ¯\n")
                f.write(f"- åŸæ–‡ä»¶: {analysis['file_path']}\n")
                f.write(f"- åŸæ–‡ä»¶è¡Œæ•°: {analysis['total_lines']}è¡Œ\n")
                f.write(f"- æ‹†åˆ†ç­–ç•¥: {split_plan['strategy']}\n\n")
                f.write(f"## æ‹†åˆ†æ–‡ä»¶åˆ—è¡¨\n\n")

                for file_name, file_info in split_plan["files"].items():
                    f.write(f"### {file_name}\n")
                    f.write(f"- **æè¿°**: {file_info['description']}\n")
                    f.write(f"- **æœ€å¤§è¡Œæ•°**: {file_info['max_lines']}è¡Œ\n")
                    f.write(f"- **åŒ…å«å†…å®¹**: {', '.join(file_info['includes'])}\n\n")

                f.write(f"## é‡æ„æ­¥éª¤\n\n")
                f.write(f"1. åˆ†æåŸæ–‡ä»¶ä¸­çš„ç±»å’Œæ–¹æ³•\n")
                f.write(f"2. æŒ‰ç…§å•ä¸€èŒè´£åŸåˆ™å°†ä»£ç åˆ†é…åˆ°å¯¹åº”æ–‡ä»¶\n")
                f.write(f"3. ç¡®ä¿æ¯ä¸ªæ–‡ä»¶ä¸è¶…è¿‡è¡Œæ•°é™åˆ¶\n")
                f.write(f"4. ä½¿ç”¨transfunctionsæ›¿æ¢é‡å¤å®ç°\n")
                f.write(f"5. æ›´æ–°å¯¼å…¥è¯­å¥å’Œä¾èµ–å…³ç³»\n")
                f.write(f"6. è¿è¡Œæµ‹è¯•ç¡®ä¿åŠŸèƒ½æ­£å¸¸\n\n")
                f.write(f"## æ³¨æ„äº‹é¡¹\n\n")
                f.write(f"- ä¸¥æ ¼éµå¾ªå•ä¸€èŒè´£åŸåˆ™\n")
                f.write(f"- é¿å…å¾ªç¯ä¾èµ–\n")
                f.write(f"- ä¿æŒæ¥å£çš„å‘åå…¼å®¹æ€§\n")
                f.write(f"- ä½¿ç”¨ç±»å‹æ³¨è§£å’Œæ–‡æ¡£å­—ç¬¦ä¸²\n")

            print(f"ğŸ“– åˆ›å»ºé‡æ„æŒ‡å—: {guide_file}")
            print(f"âœ… æ‹†åˆ†è®¡åˆ’æ‰§è¡Œå®Œæˆ")

            return True

        except Exception as e:
            print(f"âŒ æ‰§è¡Œæ‹†åˆ†è®¡åˆ’æ—¶å‡ºé”™: {e}")
            return False


def main():
    """ä¸»å‡½æ•°"""
    print("ğŸ”§ å¼€å§‹æ‰«æå’Œæ‹†åˆ†è¶…å¤§æ–‡ä»¶...")

    # æ‰«æUIç»„ä»¶ç›®å½•
    ui_components_dir = Path("src/minicrm/ui/components")

    if not ui_components_dir.exists():
        print(f"âŒ ç›®å½•ä¸å­˜åœ¨: {ui_components_dir}")
        return

    splitter = FileSplitter(max_lines=200)

    # éœ€è¦æ‹†åˆ†çš„æ–‡ä»¶åˆ—è¡¨
    large_files = []

    # æ‰«ææ‰€æœ‰Pythonæ–‡ä»¶
    for py_file in ui_components_dir.glob("*.py"):
        if py_file.name == "__init__.py":
            continue

        # æ£€æŸ¥æ–‡ä»¶è¡Œæ•°
        try:
            with open(py_file, "r", encoding="utf-8") as f:
                line_count = len(f.readlines())

            if line_count > 200:
                large_files.append((py_file, line_count))
                print(f"ğŸ“ å‘ç°è¶…å¤§æ–‡ä»¶: {py_file.name} ({line_count}è¡Œ)")
        except Exception as e:
            print(f"âŒ æ£€æŸ¥æ–‡ä»¶ {py_file} æ—¶å‡ºé”™: {e}")

    if not large_files:
        print("âœ… æ²¡æœ‰å‘ç°è¶…è¿‡200è¡Œçš„æ–‡ä»¶")
        return

    print(f"\nğŸ“Š å‘ç° {len(large_files)} ä¸ªéœ€è¦æ‹†åˆ†çš„æ–‡ä»¶:")
    for file_path, line_count in large_files:
        print(f"   - {file_path.name}: {line_count}è¡Œ")

    # ä¸ºæ¯ä¸ªå¤§æ–‡ä»¶åˆ›å»ºæ‹†åˆ†è®¡åˆ’
    for file_path, line_count in large_files:
        print(f"\nğŸ” åˆ†ææ–‡ä»¶: {file_path.name}")

        analysis = splitter.analyze_file(file_path)
        if not analysis:
            continue

        split_plan = splitter.create_split_plan(analysis)
        if not split_plan:
            print(f"   â„¹ï¸  æ–‡ä»¶ä¸éœ€è¦æ‹†åˆ†")
            continue

        print(f"   ğŸ“‹ åˆ›å»ºæ‹†åˆ†è®¡åˆ’: {split_plan['strategy']} ç­–ç•¥")
        print(f"   ğŸ“‚ ç›®æ ‡ç›®å½•: {split_plan['base_dir']}")
        print(f"   ğŸ“„ æ‹†åˆ†ä¸º {len(split_plan['files'])} ä¸ªæ–‡ä»¶")

        # æ‰§è¡Œæ‹†åˆ†è®¡åˆ’
        success = splitter.execute_split_plan(analysis, split_plan)
        if success:
            print(f"   âœ… æ‹†åˆ†å®Œæˆ")
        else:
            print(f"   âŒ æ‹†åˆ†å¤±è´¥")

    print(f"\nğŸ¯ ä¸‹ä¸€æ­¥:")
    print(f"   1. æŸ¥çœ‹å„ä¸ªç›®å½•ä¸­çš„ REFACTOR_GUIDE.md æ–‡ä»¶")
    print(f"   2. æŒ‰ç…§æŒ‡å—æ‰‹åŠ¨é‡æ„ä»£ç ")
    print(f"   3. ç¡®ä¿æ¯ä¸ªæ–‡ä»¶ä¸è¶…è¿‡200è¡Œ")
    print(f"   4. ä½¿ç”¨transfunctionsæ›¿æ¢é‡å¤å®ç°")
    print(f"   5. è¿è¡Œæµ‹è¯•éªŒè¯åŠŸèƒ½æ­£å¸¸")


if __name__ == "__main__":
    main()
