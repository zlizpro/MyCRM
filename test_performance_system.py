#!/usr/bin/env python3
"""MiniCRMæ€§èƒ½æµ‹è¯•ç³»ç»ŸéªŒè¯è„šæœ¬

å¿«é€ŸéªŒè¯æ€§èƒ½æµ‹è¯•ç³»ç»Ÿæ˜¯å¦æ­£å¸¸å·¥ä½œã€‚
"""

from pathlib import Path
import sys
import time


# æ·»åŠ é¡¹ç›®è·¯å¾„
project_root = Path(__file__).parent
sys.path.insert(0, str(project_root / "src"))
sys.path.insert(0, str(project_root))


def test_performance_framework():
    """æµ‹è¯•æ€§èƒ½æµ‹è¯•æ¡†æ¶"""
    print("ğŸ§ª æµ‹è¯•æ€§èƒ½æµ‹è¯•æ¡†æ¶...")

    try:
        from tests.performance.performance_benchmark_framework import (
            PerformanceMetrics,
            PerformanceMonitor,
        )

        # æµ‹è¯•æ€§èƒ½æŒ‡æ ‡
        metrics = PerformanceMetrics()
        metrics.startup_time = 2.5
        metrics.peak_memory = 150.0
        print("âœ… PerformanceMetrics åˆ›å»ºæˆåŠŸ")

        # æµ‹è¯•æ€§èƒ½ç›‘æ§å™¨
        monitor = PerformanceMonitor()
        monitor.start_monitoring()
        time.sleep(0.1)
        stats = monitor.stop_monitoring()
        print("âœ… PerformanceMonitor å·¥ä½œæ­£å¸¸")

        return True

    except Exception as e:
        print(f"âŒ æ€§èƒ½æ¡†æ¶æµ‹è¯•å¤±è´¥: {e}")
        return False


def test_startup_benchmark():
    """æµ‹è¯•å¯åŠ¨æ€§èƒ½åŸºå‡†"""
    print("ğŸš€ æµ‹è¯•å¯åŠ¨æ€§èƒ½åŸºå‡†...")

    try:
        from tests.performance.startup_performance_test import (
            ApplicationStartupBenchmark,
        )

        benchmark = ApplicationStartupBenchmark()
        print("âœ… ApplicationStartupBenchmark åˆ›å»ºæˆåŠŸ")

        # åªæµ‹è¯•TTKç‰ˆæœ¬ï¼ˆé¿å…Qtä¾èµ–é—®é¢˜ï¼‰
        ttk_metrics = benchmark.run_ttk_test()

        if ttk_metrics.startup_time > 0:
            print(f"âœ… TTKå¯åŠ¨æµ‹è¯•å®Œæˆ: {ttk_metrics.startup_time:.3f}ç§’")
        else:
            print("âš ï¸ TTKå¯åŠ¨æµ‹è¯•è¿”å›æ— æ•ˆç»“æœ")

        return True

    except Exception as e:
        print(f"âŒ å¯åŠ¨æ€§èƒ½æµ‹è¯•å¤±è´¥: {e}")
        return False


def test_memory_benchmark():
    """æµ‹è¯•å†…å­˜æ€§èƒ½åŸºå‡†"""
    print("ğŸ’¾ æµ‹è¯•å†…å­˜æ€§èƒ½åŸºå‡†...")

    try:
        from tests.performance.memory_usage_benchmark import MemoryUsageBenchmark

        benchmark = MemoryUsageBenchmark()
        print("âœ… MemoryUsageBenchmark åˆ›å»ºæˆåŠŸ")

        # åªæµ‹è¯•TTKç‰ˆæœ¬
        ttk_metrics = benchmark.run_ttk_test()

        if ttk_metrics.peak_memory > 0:
            print(f"âœ… TTKå†…å­˜æµ‹è¯•å®Œæˆ: {ttk_metrics.peak_memory:.1f}MB")
        else:
            print("âš ï¸ TTKå†…å­˜æµ‹è¯•è¿”å›æ— æ•ˆç»“æœ")

        return True

    except Exception as e:
        print(f"âŒ å†…å­˜æ€§èƒ½æµ‹è¯•å¤±è´¥: {e}")
        return False


def test_report_generator():
    """æµ‹è¯•æŠ¥å‘Šç”Ÿæˆå™¨"""
    print("ğŸ“Š æµ‹è¯•æŠ¥å‘Šç”Ÿæˆå™¨...")

    try:
        from tests.performance.performance_report_generator import (
            ComprehensiveReportGenerator,
        )

        generator = ComprehensiveReportGenerator("test_reports")
        print("âœ… ComprehensiveReportGenerator åˆ›å»ºæˆåŠŸ")

        # åˆ›å»ºæµ‹è¯•æ•°æ®
        test_data = {
            "timestamp": "2024-01-01T12:00:00",
            "summary": {
                "total_tests": 2,
                "qt_success_rate": 1.0,
                "ttk_success_rate": 1.0,
            },
            "detailed_results": [],
            "performance_analysis": {"overall_assessment": "è‰¯å¥½", "bottlenecks": []},
            "compliance_check": {"overall_compliant": True, "failed_requirements": []},
            "optimization_recommendations": [],
            "system_info": {"platform": "Test Platform", "python_version": "3.9.0"},
        }

        # ç”ŸæˆæŠ¥å‘Š
        files = generator.generate_comprehensive_report(test_data)

        if files:
            print(f"âœ… æŠ¥å‘Šç”ŸæˆæˆåŠŸ: {len(files)}ä¸ªæ–‡ä»¶")
            for file_type, file_path in files.items():
                if Path(file_path).exists():
                    print(f"   ğŸ“„ {file_type}: {file_path}")
                else:
                    print(f"   âŒ {file_type}: æ–‡ä»¶æœªç”Ÿæˆ")
        else:
            print("âš ï¸ æœªç”Ÿæˆä»»ä½•æŠ¥å‘Šæ–‡ä»¶")

        return True

    except Exception as e:
        print(f"âŒ æŠ¥å‘Šç”Ÿæˆå™¨æµ‹è¯•å¤±è´¥: {e}")
        return False


def main():
    """ä¸»å‡½æ•°"""
    print("ğŸ” MiniCRMæ€§èƒ½æµ‹è¯•ç³»ç»ŸéªŒè¯")
    print("=" * 50)

    tests = [
        ("æ€§èƒ½æ¡†æ¶", test_performance_framework),
        ("å¯åŠ¨åŸºå‡†", test_startup_benchmark),
        ("å†…å­˜åŸºå‡†", test_memory_benchmark),
        ("æŠ¥å‘Šç”Ÿæˆ", test_report_generator),
    ]

    passed = 0
    total = len(tests)

    for test_name, test_func in tests:
        print(f"\nğŸ“‹ {test_name}æµ‹è¯•:")
        print("-" * 30)

        try:
            if test_func():
                passed += 1
                print(f"âœ… {test_name}æµ‹è¯•é€šè¿‡")
            else:
                print(f"âŒ {test_name}æµ‹è¯•å¤±è´¥")
        except Exception as e:
            print(f"âŒ {test_name}æµ‹è¯•å¼‚å¸¸: {e}")

    print("\n" + "=" * 50)
    print(f"ğŸ“ˆ æµ‹è¯•ç»“æœ: {passed}/{total} é€šè¿‡")

    if passed == total:
        print("ğŸ‰ æ‰€æœ‰æµ‹è¯•é€šè¿‡ï¼æ€§èƒ½æµ‹è¯•ç³»ç»Ÿå·¥ä½œæ­£å¸¸ã€‚")
        return 0
    print("âš ï¸ éƒ¨åˆ†æµ‹è¯•å¤±è´¥ï¼Œè¯·æ£€æŸ¥ç³»ç»Ÿé…ç½®ã€‚")
    return 1


if __name__ == "__main__":
    sys.exit(main())
