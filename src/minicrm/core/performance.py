"""MiniCRM æ€§èƒ½ä¼˜åŒ–æ ¸å¿ƒæ¨¡å—
æä¾›å†…å­˜ç®¡ç†ã€ç¼“å­˜ã€æ€§èƒ½ç›‘æ§ç­‰åŠŸèƒ½
"""

import gc
import threading
import time
from collections.abc import Callable
from contextlib import contextmanager
from functools import wraps
from typing import Any

import psutil


class MemoryManager:
    """å†…å­˜ç®¡ç†å™¨ - ç›‘æ§å’Œä¼˜åŒ–å†…å­˜ä½¿ç”¨"""

    def __init__(
        self, warning_threshold_mb: int = 200, critical_threshold_mb: int = 400
    ):
        self.warning_threshold = warning_threshold_mb * 1024 * 1024  # è½¬æ¢ä¸ºå­—èŠ‚
        self.critical_threshold = critical_threshold_mb * 1024 * 1024
        self.process = psutil.Process()
        self.baseline_memory = self.get_memory_usage()

    def get_memory_usage(self) -> dict[str, float]:
        """è·å–å½“å‰å†…å­˜ä½¿ç”¨æƒ…å†µ"""
        memory_info = self.process.memory_info()
        return {
            "rss_mb": memory_info.rss / 1024 / 1024,
            "vms_mb": memory_info.vms / 1024 / 1024,
            "percent": self.process.memory_percent(),
            "available_mb": psutil.virtual_memory().available / 1024 / 1024,
        }

    def check_memory_status(self) -> dict[str, Any]:
        """æ£€æŸ¥å†…å­˜çŠ¶æ€å¹¶è¿”å›å»ºè®®"""
        current = self.get_memory_usage()
        rss_bytes = current["rss_mb"] * 1024 * 1024

        if rss_bytes > self.critical_threshold:
            status = "critical"
            suggestion = "ç«‹å³æ‰§è¡Œåƒåœ¾å›æ”¶å’Œå†…å­˜æ¸…ç†"
        elif rss_bytes > self.warning_threshold:
            status = "warning"
            suggestion = "å»ºè®®æ‰§è¡Œåƒåœ¾å›æ”¶"
        else:
            status = "good"
            suggestion = "å†…å­˜ä½¿ç”¨æ­£å¸¸"

        return {
            "status": status,
            "current_mb": current["rss_mb"],
            "suggestion": suggestion,
            "details": current,
        }

    def force_garbage_collection(self) -> dict[str, Any]:
        """å¼ºåˆ¶æ‰§è¡Œåƒåœ¾å›æ”¶"""
        before = self.get_memory_usage()

        # æ‰§è¡Œåƒåœ¾å›æ”¶
        collected = gc.collect()

        after = self.get_memory_usage()
        freed_mb = before["rss_mb"] - after["rss_mb"]

        return {
            "objects_collected": collected,
            "memory_freed_mb": freed_mb,
            "before_mb": before["rss_mb"],
            "after_mb": after["rss_mb"],
        }


class SmartCache:
    """æ™ºèƒ½ç¼“å­˜ç³»ç»Ÿ - æ”¯æŒTTLå’ŒLRUç­–ç•¥"""

    def __init__(self, max_size: int = 128, ttl_seconds: int = 300):
        self.max_size = max_size
        self.ttl_seconds = ttl_seconds
        self.cache: dict[str, Any] = {}
        self.access_times: dict[str, float] = {}
        self.hit_count = 0
        self.miss_count = 0
        self._lock = threading.RLock()

    def get(self, key: str) -> Any | None:
        """è·å–ç¼“å­˜å€¼"""
        with self._lock:
            if key not in self.cache:
                self.miss_count += 1
                return None

            # æ£€æŸ¥æ˜¯å¦è¿‡æœŸ
            if time.time() - self.access_times[key] > self.ttl_seconds:
                del self.cache[key]
                del self.access_times[key]
                self.miss_count += 1
                return None

            # æ›´æ–°è®¿é—®æ—¶é—´
            self.access_times[key] = time.time()
            self.hit_count += 1
            return self.cache[key]

    def set(self, key: str, value: Any) -> None:
        """è®¾ç½®ç¼“å­˜å€¼"""
        with self._lock:
            # æ¸…ç†è¿‡æœŸé¡¹
            self._cleanup_expired()

            # å¦‚æœç¼“å­˜æ»¡äº†ï¼Œåˆ é™¤æœ€æ—§çš„é¡¹
            if len(self.cache) >= self.max_size and key not in self.cache:
                oldest_key = min(
                    self.access_times.keys(), key=lambda k: self.access_times[k]
                )
                del self.cache[oldest_key]
                del self.access_times[oldest_key]

            self.cache[key] = value
            self.access_times[key] = time.time()

    def _cleanup_expired(self) -> None:
        """æ¸…ç†è¿‡æœŸçš„ç¼“å­˜é¡¹"""
        current_time = time.time()
        expired_keys = [
            key
            for key, access_time in self.access_times.items()
            if current_time - access_time > self.ttl_seconds
        ]

        for key in expired_keys:
            del self.cache[key]
            del self.access_times[key]

    def get_stats(self) -> dict[str, Any]:
        """è·å–ç¼“å­˜ç»Ÿè®¡ä¿¡æ¯"""
        total_requests = self.hit_count + self.miss_count
        hit_rate = (self.hit_count / total_requests * 100) if total_requests > 0 else 0

        return {
            "size": len(self.cache),
            "max_size": self.max_size,
            "hit_count": self.hit_count,
            "miss_count": self.miss_count,
            "hit_rate_percent": hit_rate,
            "memory_usage_mb": self._estimate_memory_usage(),
        }

    def _estimate_memory_usage(self) -> float:
        """ä¼°ç®—ç¼“å­˜å†…å­˜ä½¿ç”¨é‡"""
        import sys

        total_size = 0
        for key, value in self.cache.items():
            total_size += sys.getsizeof(key) + sys.getsizeof(value)
        return total_size / 1024 / 1024  # è½¬æ¢ä¸ºMB


def performance_monitor(func_name: str | None = None):
    """æ€§èƒ½ç›‘æ§è£…é¥°å™¨"""

    def decorator(func: Callable) -> Callable:
        name = func_name or f"{func.__module__}.{func.__name__}"

        @wraps(func)
        def wrapper(*args, **kwargs):
            start_time = time.time()
            start_memory = psutil.Process().memory_info().rss

            try:
                result = func(*args, **kwargs)
                return result
            finally:
                end_time = time.time()
                end_memory = psutil.Process().memory_info().rss

                execution_time = end_time - start_time
                memory_delta = (end_memory - start_memory) / 1024 / 1024  # MB

                # è®°å½•æ€§èƒ½æ•°æ®
                PerformanceTracker.instance().record_execution(
                    name,
                    execution_time,
                    memory_delta,
                )

                # å¦‚æœæ‰§è¡Œæ—¶é—´è¿‡é•¿ï¼Œå‘å‡ºè­¦å‘Š
                if execution_time > 1.0:  # 1ç§’
                    print(f"âš ï¸ æ…¢æ“ä½œæ£€æµ‹: {name} è€—æ—¶ {execution_time:.2f}ç§’")

        return wrapper

    return decorator


class PerformanceTracker:
    """æ€§èƒ½è·Ÿè¸ªå™¨ - å•ä¾‹æ¨¡å¼"""

    _instance = None
    _lock = threading.Lock()

    def __new__(cls):
        if cls._instance is None:
            with cls._lock:
                if cls._instance is None:
                    cls._instance = super().__new__(cls)
                    cls._instance._initialized = False
        return cls._instance

    def __init__(self):
        if self._initialized:
            return

        self.execution_times: dict[str, list] = {}
        self.memory_deltas: dict[str, list] = {}
        self._lock = threading.RLock()
        self._initialized = True

    @classmethod
    def instance(cls):
        return cls()

    def record_execution(
        self, func_name: str, execution_time: float, memory_delta: float
    ):
        """è®°å½•å‡½æ•°æ‰§è¡Œæ€§èƒ½"""
        with self._lock:
            if func_name not in self.execution_times:
                self.execution_times[func_name] = []
                self.memory_deltas[func_name] = []

            self.execution_times[func_name].append(execution_time)
            self.memory_deltas[func_name].append(memory_delta)

            # ä¿æŒæœ€è¿‘100æ¬¡è®°å½•
            if len(self.execution_times[func_name]) > 100:
                self.execution_times[func_name] = self.execution_times[func_name][-100:]
                self.memory_deltas[func_name] = self.memory_deltas[func_name][-100:]

    def get_performance_summary(self) -> dict[str, dict[str, float]]:
        """è·å–æ€§èƒ½æ‘˜è¦"""
        summary = {}

        with self._lock:
            for func_name in self.execution_times:
                times = self.execution_times[func_name]
                memories = self.memory_deltas[func_name]

                if times:
                    summary[func_name] = {
                        "avg_time": sum(times) / len(times),
                        "max_time": max(times),
                        "min_time": min(times),
                        "call_count": len(times),
                        "avg_memory_delta": sum(memories) / len(memories),
                        "max_memory_delta": max(memories),
                    }

        return summary

    def get_slowest_functions(self, top_n: int = 10) -> list:
        """è·å–æœ€æ…¢çš„å‡½æ•°"""
        summary = self.get_performance_summary()
        sorted_funcs = sorted(
            summary.items(), key=lambda x: x[1]["avg_time"], reverse=True
        )
        return sorted_funcs[:top_n]


@contextmanager
def memory_context(description: str = "æ“ä½œ"):
    """å†…å­˜ä½¿ç”¨ä¸Šä¸‹æ–‡ç®¡ç†å™¨"""
    manager = MemoryManager()
    before = manager.get_memory_usage()

    print(f"ğŸ” å¼€å§‹{description} - å†…å­˜ä½¿ç”¨: {before['rss_mb']:.1f}MB")

    try:
        yield manager
    finally:
        after = manager.get_memory_usage()
        delta = after["rss_mb"] - before["rss_mb"]

        if delta > 10:  # 10MB
            print(f"âš ï¸ {description}å®Œæˆ - å†…å­˜å¢åŠ : {delta:.1f}MB")
        else:
            print(f"âœ… {description}å®Œæˆ - å†…å­˜å˜åŒ–: {delta:+.1f}MB")


# å…¨å±€å®ä¾‹
memory_manager = MemoryManager()
global_cache = SmartCache()
performance_tracker = PerformanceTracker.instance()
