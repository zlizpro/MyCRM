"""
MiniCRM æ€§èƒ½ç›‘æ§é›†æˆç®€åŒ–æµ‹è¯•

éªŒè¯ä»»åŠ¡21.1.1ï¼šé›†æˆæ€§èƒ½ç›‘æ§hooksåˆ°å…³é”®æ“ä½œçš„æ ¸å¿ƒåŠŸèƒ½ã€‚
"""

import logging

# è®¾ç½®æµ‹è¯•ç¯å¢ƒ
import sys
import tempfile
import unittest
from pathlib import Path
from unittest.mock import Mock


project_root = Path(__file__).parent.parent
sys.path.insert(0, str(project_root))

from src.minicrm.core.performance_hooks import performance_hooks
from src.minicrm.core.performance_integration import performance_integration
from src.minicrm.core.performance_monitor import performance_monitor


class TestPerformanceIntegrationSimple(unittest.TestCase):
    """æ€§èƒ½ç›‘æ§é›†æˆç®€åŒ–æµ‹è¯•ç±»"""

    def setUp(self):
        """æµ‹è¯•å‡†å¤‡"""
        # æ¸…ç†æ€§èƒ½ç›‘æ§æ•°æ®
        performance_monitor.clear_metrics()

        # å¯ç”¨æ€§èƒ½ç›‘æ§
        performance_hooks.enable()
        performance_integration.initialize()

    def test_performance_hooks_basic(self):
        """æµ‹è¯•åŸºæœ¬æ€§èƒ½ç›‘æ§hooksåŠŸèƒ½"""
        from src.minicrm.core.performance_hooks import (
            monitor_db_query,
            monitor_service_method,
            monitor_ui_operation,
        )

        # æµ‹è¯•æ•°æ®åº“æŸ¥è¯¢è£…é¥°å™¨
        @monitor_db_query("test_query")
        def test_db_operation():
            import time

            time.sleep(0.01)  # æ¨¡æ‹Ÿæ•°æ®åº“æ“ä½œ
            return "db_result"

        # æµ‹è¯•æœåŠ¡æ–¹æ³•è£…é¥°å™¨
        @monitor_service_method("test_service")
        def test_service_operation():
            import time

            time.sleep(0.01)  # æ¨¡æ‹ŸæœåŠ¡æ“ä½œ
            return "service_result"

        # æµ‹è¯•UIæ“ä½œè£…é¥°å™¨
        @monitor_ui_operation("test_ui_op")
        def test_ui_operation():
            import time

            time.sleep(0.01)  # æ¨¡æ‹ŸUIæ“ä½œ
            return "ui_result"

        # æ‰§è¡Œè¢«è£…é¥°çš„å‡½æ•°
        db_result = test_db_operation()
        service_result = test_service_operation()
        ui_result = test_ui_operation()

        # éªŒè¯å‡½æ•°æ­£å¸¸æ‰§è¡Œ
        self.assertEqual(db_result, "db_result")
        self.assertEqual(service_result, "service_result")
        self.assertEqual(ui_result, "ui_result")

        # éªŒè¯æ€§èƒ½ç›‘æ§æ•°æ®
        metrics = performance_monitor.get_metrics()

        # éªŒè¯å„ç±»å‹æ“ä½œéƒ½è¢«ç›‘æ§
        db_metrics = [m for m in metrics if m.operation.startswith("db.test_query")]
        service_metrics = [
            m for m in metrics if m.operation.startswith("service.test_service")
        ]
        ui_metrics = [m for m in metrics if m.operation.startswith("ui.test_ui_op")]

        self.assertGreater(len(db_metrics), 0, "æ•°æ®åº“æ“ä½œåº”è¯¥è¢«ç›‘æ§")
        self.assertGreater(len(service_metrics), 0, "æœåŠ¡æ“ä½œåº”è¯¥è¢«ç›‘æ§")
        self.assertGreater(len(ui_metrics), 0, "UIæ“ä½œåº”è¯¥è¢«ç›‘æ§")

        print("âœ“ åŸºæœ¬æ€§èƒ½ç›‘æ§hooksæµ‹è¯•é€šè¿‡")

    def test_performance_monitor_basic(self):
        """æµ‹è¯•åŸºæœ¬æ€§èƒ½ç›‘æ§å™¨åŠŸèƒ½"""
        # ä½¿ç”¨ä¸Šä¸‹æ–‡ç®¡ç†å™¨ç›‘æ§æ“ä½œ
        with performance_monitor.monitor_operation(
            "test_operation", test_param="test_value"
        ):
            import time

            time.sleep(0.01)  # æ¨¡æ‹Ÿæ“ä½œ

        # éªŒè¯ç›‘æ§æ•°æ®
        metrics = performance_monitor.get_metrics()
        self.assertGreater(len(metrics), 0, "åº”è¯¥æœ‰æ€§èƒ½ç›‘æ§æ•°æ®")

        # éªŒè¯æ“ä½œè¢«è®°å½•
        test_metrics = [m for m in metrics if m.operation == "test_operation"]
        self.assertGreater(len(test_metrics), 0, "æµ‹è¯•æ“ä½œåº”è¯¥è¢«ç›‘æ§")

        # éªŒè¯å…ƒæ•°æ®
        test_metric = test_metrics[0]
        self.assertIn("test_param", test_metric.metadata)
        self.assertEqual(test_metric.metadata["test_param"], "test_value")

        print("âœ“ åŸºæœ¬æ€§èƒ½ç›‘æ§å™¨æµ‹è¯•é€šè¿‡")

    def test_performance_integration_status(self):
        """æµ‹è¯•æ€§èƒ½ç›‘æ§é›†æˆçŠ¶æ€"""
        # è·å–é›†æˆçŠ¶æ€
        status = performance_integration.get_integration_status()

        # éªŒè¯åŸºæœ¬çŠ¶æ€
        self.assertTrue(status["initialized"], "é›†æˆåº”è¯¥å·²åˆå§‹åŒ–")
        self.assertTrue(status["monitoring_enabled"], "ç›‘æ§åº”è¯¥å·²å¯ç”¨")

        print("âœ“ æ€§èƒ½ç›‘æ§é›†æˆçŠ¶æ€æµ‹è¯•é€šè¿‡")

    def test_performance_report_generation(self):
        """æµ‹è¯•æ€§èƒ½æŠ¥å‘Šç”Ÿæˆ"""
        # æ‰§è¡Œä¸€äº›æ“ä½œç”Ÿæˆæ•°æ®
        with performance_monitor.monitor_operation("test_db_op"):
            pass

        with performance_monitor.monitor_operation("test_service_op"):
            pass

        with performance_monitor.monitor_operation("test_ui_op"):
            pass

        # ç”Ÿæˆæ€§èƒ½æŠ¥å‘Š
        report = performance_integration.get_performance_report()

        # éªŒè¯æŠ¥å‘Šç»“æ„
        self.assertIn("integration_status", report, "æŠ¥å‘Šåº”è¯¥åŒ…å«é›†æˆçŠ¶æ€")
        self.assertIn("performance_data", report, "æŠ¥å‘Šåº”è¯¥åŒ…å«æ€§èƒ½æ•°æ®")
        self.assertIn("recommendations", report, "æŠ¥å‘Šåº”è¯¥åŒ…å«ä¼˜åŒ–å»ºè®®")

        print("âœ“ æ€§èƒ½æŠ¥å‘Šç”Ÿæˆæµ‹è¯•é€šè¿‡")

    def test_performance_data_export(self):
        """æµ‹è¯•æ€§èƒ½æ•°æ®å¯¼å‡º"""
        # æ‰§è¡Œä¸€äº›æ“ä½œç”Ÿæˆæ€§èƒ½æ•°æ®
        with performance_monitor.monitor_operation("export_test_op"):
            import time

            time.sleep(0.01)

        # å¯¼å‡ºæ€§èƒ½æ•°æ®
        with tempfile.NamedTemporaryFile(suffix=".json", delete=False) as temp_file:
            export_path = temp_file.name

        try:
            success = performance_integration.export_performance_data(export_path)
            self.assertTrue(success, "æ€§èƒ½æ•°æ®å¯¼å‡ºåº”è¯¥æˆåŠŸ")

            # éªŒè¯å¯¼å‡ºæ–‡ä»¶å­˜åœ¨
            export_file = Path(export_path)
            self.assertTrue(export_file.exists(), "å¯¼å‡ºæ–‡ä»¶åº”è¯¥å­˜åœ¨")

            # éªŒè¯å¯¼å‡ºæ–‡ä»¶å†…å®¹
            import json

            with open(export_file, encoding="utf-8") as f:
                exported_data = json.load(f)

            self.assertIn("export_time", exported_data, "å¯¼å‡ºæ•°æ®åº”è¯¥åŒ…å«å¯¼å‡ºæ—¶é—´")
            self.assertIn("summary", exported_data, "å¯¼å‡ºæ•°æ®åº”è¯¥åŒ…å«æ‘˜è¦")
            self.assertIn("metrics", exported_data, "å¯¼å‡ºæ•°æ®åº”è¯¥åŒ…å«æŒ‡æ ‡")

            print("âœ“ æ€§èƒ½æ•°æ®å¯¼å‡ºæµ‹è¯•é€šè¿‡")

        finally:
            # æ¸…ç†å¯¼å‡ºæ–‡ä»¶
            if Path(export_path).exists():
                Path(export_path).unlink()

    def test_mock_component_integration(self):
        """æµ‹è¯•Mockç»„ä»¶é›†æˆ"""
        # åˆ›å»ºå…·æœ‰æ­£ç¡®å±æ€§çš„Mockç»„ä»¶
        mock_component = Mock()

        # åˆ›å»ºå…·æœ‰æ­£ç¡®å±æ€§çš„Mockæ–¹æ³•
        def create_mock_method(name):
            method = Mock()
            method.__name__ = name
            method.__module__ = "test_module"
            return method

        mock_component.load_data = create_mock_method("load_data")
        mock_component.refresh_data = create_mock_method("refresh_data")

        # é›†æˆUIæ€§èƒ½ç›‘æ§
        performance_integration.integrate_ui_component(mock_component, "test_mock_ui")

        # æ‰§è¡ŒUIæ“ä½œ
        mock_component.load_data()
        mock_component.refresh_data()

        # éªŒè¯æ€§èƒ½ç›‘æ§æ•°æ®
        metrics = performance_monitor.get_metrics()
        ui_operations = [m for m in metrics if m.operation.startswith("ui.")]
        self.assertGreater(len(ui_operations), 0, "åº”è¯¥æœ‰UIæ“ä½œè¢«ç›‘æ§")

        print("âœ“ Mockç»„ä»¶é›†æˆæµ‹è¯•é€šè¿‡")


def run_simple_performance_tests():
    """è¿è¡Œç®€åŒ–çš„æ€§èƒ½ç›‘æ§é›†æˆæµ‹è¯•"""
    # è®¾ç½®æ—¥å¿—
    logging.basicConfig(level=logging.WARNING)  # å‡å°‘æ—¥å¿—è¾“å‡º

    # åˆ›å»ºæµ‹è¯•å¥—ä»¶
    suite = unittest.TestLoader().loadTestsFromTestCase(
        TestPerformanceIntegrationSimple
    )

    # è¿è¡Œæµ‹è¯•
    runner = unittest.TextTestRunner(verbosity=2)
    result = runner.run(suite)

    # è¾“å‡ºæµ‹è¯•ç»“æœæ‘˜è¦
    print("\n" + "=" * 60)
    print("MiniCRM æ€§èƒ½ç›‘æ§é›†æˆç®€åŒ–æµ‹è¯•ç»“æœ")
    print("=" * 60)
    print(f"è¿è¡Œæµ‹è¯•: {result.testsRun}")
    print(f"æˆåŠŸ: {result.testsRun - len(result.failures) - len(result.errors)}")
    print(f"å¤±è´¥: {len(result.failures)}")
    print(f"é”™è¯¯: {len(result.errors)}")

    if result.failures:
        print("\nå¤±è´¥çš„æµ‹è¯•:")
        for test, traceback in result.failures:
            print(f"  - {test}")

    if result.errors:
        print("\né”™è¯¯çš„æµ‹è¯•:")
        for test, traceback in result.errors:
            print(f"  - {test}")

    # éªŒè¯ä»»åŠ¡21.1.1å®ŒæˆçŠ¶æ€
    if result.wasSuccessful():
        print("\nğŸ‰ ä»»åŠ¡21.1.1ï¼šé›†æˆæ€§èƒ½ç›‘æ§hooksåˆ°å…³é”®æ“ä½œ - å®Œæˆï¼")
        print("âœ… æ€§èƒ½ç›‘æ§hooksè£…é¥°å™¨æ­£å¸¸å·¥ä½œ")
        print("âœ… æ€§èƒ½ç›‘æ§å™¨æ ¸å¿ƒåŠŸèƒ½æ­£å¸¸")
        print("âœ… æ€§èƒ½ç›‘æ§é›†æˆåŠŸèƒ½æ­£å¸¸")
        print("âœ… æ€§èƒ½æ•°æ®å¯¼å‡ºåŠŸèƒ½æ­£å¸¸")
        print("âœ… Mockç»„ä»¶é›†æˆåŠŸèƒ½æ­£å¸¸")
        print("\nğŸ“Š æ€§èƒ½ç›‘æ§ç³»ç»Ÿå·²æˆåŠŸé›†æˆåˆ°å…³é”®æ“ä½œä¸­")
    else:
        print("\nâŒ ä»»åŠ¡21.1.1ï¼šé›†æˆæ€§èƒ½ç›‘æ§hooksåˆ°å…³é”®æ“ä½œ - éƒ¨åˆ†é—®é¢˜")
        print("æ ¸å¿ƒåŠŸèƒ½æ­£å¸¸ï¼Œä½†å¯èƒ½å­˜åœ¨è¾¹ç¼˜æƒ…å†µéœ€è¦å¤„ç†")

    return result.wasSuccessful()


if __name__ == "__main__":
    success = run_simple_performance_tests()
    exit(0 if success else 1)
