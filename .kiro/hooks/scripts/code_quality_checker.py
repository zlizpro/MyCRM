#!/usr/bin/env python3
"""
MiniCRM ä»£ç è´¨é‡æ£€æŸ¥å™¨
è‡ªåŠ¨æ£€æŸ¥Pythonä»£ç çš„è´¨é‡ï¼ŒåŒ…æ‹¬PEP8ã€ç±»å‹æ³¨è§£ã€æ–‡æ¡£å­—ç¬¦ä¸²ç­‰
"""

import ast
import re
import sys
import json
import argparse
from pathlib import Path
from typing import List, Dict, Any, Optional, Tuple
from dataclasses import dataclass
from datetime import datetime


@dataclass
class QualityIssue:
    """ä»£ç è´¨é‡é—®é¢˜æ•°æ®ç±»"""
    file_path: str
    line_number: int
    column: int
    issue_type: str
    severity: str  # 'error', 'warning', 'info'
    message: str
    suggestion: Optional[str] = None
    auto_fixable: bool = False


class CodeQualityChecker:
    """ä»£ç è´¨é‡æ£€æŸ¥å™¨ä¸»ç±»"""

    def __init__(self, config: Dict[str, Any]):
        self.config = config
        self.issues: List[QualityIssue] = []

    def check_file(self, file_path: Path) -> List[QualityIssue]:
        """æ£€æŸ¥å•ä¸ªPythonæ–‡ä»¶çš„ä»£ç è´¨é‡"""
        self.issues = []

        try:
            with open(file_path, 'r', encoding='utf-8') as f:
                content = f.read()

            # è§£æAST
            try:
                tree = ast.parse(content)
            except SyntaxError as e:
                self.issues.append(QualityIssue(
                    file_path=str(file_path),
                    line_number=e.lineno or 1,
                    column=e.offset or 0,
                    issue_type="syntax_error",
                    severity="error",
                    message=f"è¯­æ³•é”™è¯¯: {e.msg}",
                    auto_fixable=False
                ))
                return self.issues

            # æ‰§è¡Œå„ç§æ£€æŸ¥
            self._check_imports(content, str(file_path))
            self._check_line_length(content, str(file_path))
            self._check_naming_conventions(tree, str(file_path))
            self._check_docstrings(tree, str(file_path))
            self._check_type_hints(tree, str(file_path))
            self._check_code_structure(tree, str(file_path))

        except Exception as e:
            self.issues.append(QualityIssue(
                file_path=str(file_path),
                line_number=1,
                column=0,
                issue_type="check_error",
                severity="error",
                message=f"æ£€æŸ¥æ–‡ä»¶æ—¶å‡ºé”™: {str(e)}",
                auto_fixable=False
            ))

        return self.issues

    def _check_imports(self, content: str, file_path: str):
        """æ£€æŸ¥å¯¼å…¥è¯­å¥è§„èŒƒ"""
        lines = content.split('\n')

        # æ£€æŸ¥å¯¼å…¥é¡ºåºå’Œåˆ†ç»„
        import_sections = {'stdlib': [], 'third_party': [], 'local': []}
        current_section = None

        for i, line in enumerate(lines, 1):
            line = line.strip()
            if line.startswith('import ') or line.startswith('from '):
                # ç®€åŒ–çš„å¯¼å…¥åˆ†ç±»é€»è¾‘
                if any(stdlib in line for stdlib in ['os', 'sys', 'json', 'datetime', 're', 'pathlib']):
                    section = 'stdlib'
                elif any(third in line for third in ['tkinter', 'matplotlib', 'reportlab']):
                    section = 'third_party'
                else:
                    section = 'local'

                import_sections[section].append((i, line))

                # æ£€æŸ¥æ˜¯å¦æœ‰æœªä½¿ç”¨çš„å¯¼å…¥ï¼ˆç®€åŒ–æ£€æŸ¥ï¼‰
                module_name = self._extract_module_name(line)
                if module_name and module_name not in content:
                    self.issues.append(QualityIssue(
                        file_path=file_path,
                        line_number=i,
                        column=0,
                        issue_type="unused_import",
                        severity="warning",
                        message=f"æœªä½¿ç”¨çš„å¯¼å…¥: {module_name}",
                        suggestion=f"åˆ é™¤æœªä½¿ç”¨çš„å¯¼å…¥è¯­å¥",
                        auto_fixable=True
                    ))

    def _extract_module_name(self, import_line: str) -> str:
        """ä»å¯¼å…¥è¯­å¥ä¸­æå–æ¨¡å—å"""
        if import_line.startswith('import '):
            return import_line.replace('import ', '').split('.')[0].split(' as ')[0]
        elif import_line.startswith('from '):
            parts = import_line.split(' import ')
            if len(parts) > 1:
                return parts[1].split(',')[0].strip().split(' as ')[0]
        return ""

    def _check_line_length(self, content: str, file_path: str):
        """æ£€æŸ¥è¡Œé•¿åº¦"""
        max_length = self.config.get('max_line_length', 88)
        lines = content.split('\n')

        for i, line in enumerate(lines, 1):
            if len(line) > max_length:
                self.issues.append(QualityIssue(
                    file_path=file_path,
                    line_number=i,
                    column=max_length,
                    issue_type="line_too_long",
                    severity="warning",
                    message=f"è¡Œé•¿åº¦è¶…è¿‡{max_length}å­—ç¬¦ (å½“å‰: {len(line)})",
                    suggestion="è€ƒè™‘å°†é•¿è¡Œæ‹†åˆ†ä¸ºå¤šè¡Œ",
                    auto_fixable=True
                ))

    def _check_naming_conventions(self, tree: ast.AST, file_path: str):
        """æ£€æŸ¥å‘½åè§„èŒƒ"""
        for node in ast.walk(tree):
            if isinstance(node, ast.ClassDef):
                # ç±»ååº”è¯¥ä½¿ç”¨å¤§é©¼å³°å‘½å
                if not re.match(r'^[A-Z][a-zA-Z0-9]*$', node.name):
                    self.issues.append(QualityIssue(
                        file_path=file_path,
                        line_number=node.lineno,
                        column=node.col_offset,
                        issue_type="naming_convention",
                        severity="warning",
                        message=f"ç±»å '{node.name}' åº”ä½¿ç”¨å¤§é©¼å³°å‘½åæ³•",
                        suggestion=f"å»ºè®®æ”¹ä¸º: {self._to_pascal_case(node.name)}",
                        auto_fixable=True
                    ))

            elif isinstance(node, ast.FunctionDef):
                # å‡½æ•°ååº”è¯¥ä½¿ç”¨ä¸‹åˆ’çº¿å‘½å
                if not re.match(r'^[a-z_][a-z0-9_]*$', node.name) and not node.name.startswith('__'):
                    self.issues.append(QualityIssue(
                        file_path=file_path,
                        line_number=node.lineno,
                        column=node.col_offset,
                        issue_type="naming_convention",
                        severity="warning",
                        message=f"å‡½æ•°å '{node.name}' åº”ä½¿ç”¨ä¸‹åˆ’çº¿å‘½åæ³•",
                        suggestion=f"å»ºè®®æ”¹ä¸º: {self._to_snake_case(node.name)}",
                        auto_fixable=True
                    ))

    def _check_docstrings(self, tree: ast.AST, file_path: str):
        """æ£€æŸ¥æ–‡æ¡£å­—ç¬¦ä¸²"""
        if not self.config.get('check_docstrings', True):
            return

        for node in ast.walk(tree):
            if isinstance(node, (ast.ClassDef, ast.FunctionDef)):
                # è·³è¿‡ç§æœ‰æ–¹æ³•å’Œç‰¹æ®Šæ–¹æ³•çš„docstringæ£€æŸ¥
                if node.name.startswith('_') and not node.name.startswith('__'):
                    continue

                docstring = ast.get_docstring(node)
                if not docstring:
                    node_type = "ç±»" if isinstance(node, ast.ClassDef) else "å‡½æ•°"
                    self.issues.append(QualityIssue(
                        file_path=file_path,
                        line_number=node.lineno,
                        column=node.col_offset,
                        issue_type="missing_docstring",
                        severity="info",
                        message=f"{node_type} '{node.name}' ç¼ºå°‘æ–‡æ¡£å­—ç¬¦ä¸²",
                        suggestion=f"æ·»åŠ æè¿°{node_type}åŠŸèƒ½çš„æ–‡æ¡£å­—ç¬¦ä¸²",
                        auto_fixable=True
                    ))
                elif len(docstring.strip()) < 10:
                    self.issues.append(QualityIssue(
                        file_path=file_path,
                        line_number=node.lineno,
                        column=node.col_offset,
                        issue_type="inadequate_docstring",
                        severity="info",
                        message=f"æ–‡æ¡£å­—ç¬¦ä¸²è¿‡äºç®€çŸ­: '{node.name}'",
                        suggestion="æä¾›æ›´è¯¦ç»†çš„åŠŸèƒ½æè¿°",
                        auto_fixable=False
                    ))

    def _check_type_hints(self, tree: ast.AST, file_path: str):
        """æ£€æŸ¥ç±»å‹æ³¨è§£"""
        if not self.config.get('check_type_hints', True):
            return

        for node in ast.walk(tree):
            if isinstance(node, ast.FunctionDef):
                # è·³è¿‡ç§æœ‰æ–¹æ³•å’Œç‰¹æ®Šæ–¹æ³•
                if node.name.startswith('_'):
                    continue

                # æ£€æŸ¥å‚æ•°ç±»å‹æ³¨è§£
                for arg in node.args.args:
                    if arg.arg != 'self' and not arg.annotation:
                        self.issues.append(QualityIssue(
                            file_path=file_path,
                            line_number=node.lineno,
                            column=node.col_offset,
                            issue_type="missing_type_hint",
                            severity="info",
                            message=f"å‚æ•° '{arg.arg}' ç¼ºå°‘ç±»å‹æ³¨è§£",
                            suggestion=f"ä¸ºå‚æ•° '{arg.arg}' æ·»åŠ ç±»å‹æ³¨è§£",
                            auto_fixable=True
                        ))

                # æ£€æŸ¥è¿”å›å€¼ç±»å‹æ³¨è§£
                if not node.returns and node.name != '__init__':
                    self.issues.append(QualityIssue(
                        file_path=file_path,
                        line_number=node.lineno,
                        column=node.col_offset,
                        issue_type="missing_return_type",
                        severity="info",
                        message=f"å‡½æ•° '{node.name}' ç¼ºå°‘è¿”å›å€¼ç±»å‹æ³¨è§£",
                        suggestion=f"ä¸ºå‡½æ•° '{node.name}' æ·»åŠ è¿”å›å€¼ç±»å‹æ³¨è§£",
                        auto_fixable=True
                    ))

    def _check_code_structure(self, tree: ast.AST, file_path: str):
        """æ£€æŸ¥ä»£ç ç»“æ„"""
        for node in ast.walk(tree):
            if isinstance(node, ast.FunctionDef):
                # æ£€æŸ¥å‡½æ•°å¤æ‚åº¦ï¼ˆç®€åŒ–ç‰ˆï¼‰
                complexity = self._calculate_complexity(node)
                if complexity > 10:
                    self.issues.append(QualityIssue(
                        file_path=file_path,
                        line_number=node.lineno,
                        column=node.col_offset,
                        issue_type="high_complexity",
                        severity="warning",
                        message=f"å‡½æ•° '{node.name}' å¤æ‚åº¦è¿‡é«˜ (å¤æ‚åº¦: {complexity})",
                        suggestion="è€ƒè™‘å°†å‡½æ•°æ‹†åˆ†ä¸ºæ›´å°çš„å‡½æ•°",
                        auto_fixable=False
                    ))

    def _calculate_complexity(self, node: ast.FunctionDef) -> int:
        """è®¡ç®—å‡½æ•°çš„åœˆå¤æ‚åº¦ï¼ˆç®€åŒ–ç‰ˆï¼‰"""
        complexity = 1  # åŸºç¡€å¤æ‚åº¦

        for child in ast.walk(node):
            if isinstance(child, (ast.If, ast.While, ast.For, ast.Try, ast.With)):
                complexity += 1
            elif isinstance(child, ast.BoolOp):
                complexity += len(child.values) - 1

        return complexity

    def _to_pascal_case(self, name: str) -> str:
        """è½¬æ¢ä¸ºå¤§é©¼å³°å‘½å"""
        return ''.join(word.capitalize() for word in name.split('_'))

    def _to_snake_case(self, name: str) -> str:
        """è½¬æ¢ä¸ºä¸‹åˆ’çº¿å‘½å"""
        s1 = re.sub('(.)([A-Z][a-z]+)', r'\1_\2', name)
        return re.sub('([a-z0-9])([A-Z])', r'\1_\2', s1).lower()


def generate_report(issues: List[QualityIssue], output_format: str = 'json') -> str:
    """ç”Ÿæˆè´¨é‡æ£€æŸ¥æŠ¥å‘Š"""
    if output_format == 'json':
        report_data = {
            'timestamp': datetime.now().isoformat(),
            'total_issues': len(issues),
            'issues_by_severity': {
                'error': len([i for i in issues if i.severity == 'error']),
                'warning': len([i for i in issues if i.severity == 'warning']),
                'info': len([i for i in issues if i.severity == 'info'])
            },
            'auto_fixable_count': len([i for i in issues if i.auto_fixable]),
            'issues': [
                {
                    'file_path': issue.file_path,
                    'line_number': issue.line_number,
                    'column': issue.column,
                    'issue_type': issue.issue_type,
                    'severity': issue.severity,
                    'message': issue.message,
                    'suggestion': issue.suggestion,
                    'auto_fixable': issue.auto_fixable
                }
                for issue in issues
            ]
        }
        return json.dumps(report_data, ensure_ascii=False, indent=2)

    elif output_format == 'text':
        lines = []
        lines.append("=" * 60)
        lines.append("MiniCRM ä»£ç è´¨é‡æ£€æŸ¥æŠ¥å‘Š")
        lines.append("=" * 60)
        lines.append(f"æ£€æŸ¥æ—¶é—´: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}")
        lines.append(f"æ€»é—®é¢˜æ•°: {len(issues)}")

        if issues:
            lines.append("\né—®é¢˜è¯¦æƒ…:")
            lines.append("-" * 40)

            for issue in sorted(issues, key=lambda x: (x.severity, x.file_path, x.line_number)):
                severity_icon = {"error": "âŒ", "warning": "âš ï¸", "info": "â„¹ï¸"}
                fix_icon = "ğŸ”§" if issue.auto_fixable else "ğŸ“"

                lines.append(
                    f"\n{severity_icon[issue.severity]} {fix_icon} {issue.file_path}:{issue.line_number}:{issue.column}")
                lines.append(f"   ç±»å‹: {issue.issue_type}")
                lines.append(f"   é—®é¢˜: {issue.message}")
                if issue.suggestion:
                    lines.append(f"   å»ºè®®: {issue.suggestion}")
        else:
            lines.append("\nğŸ‰ æ­å–œï¼æ²¡æœ‰å‘ç°ä»£ç è´¨é‡é—®é¢˜ã€‚")

        return "\n".join(lines)


def main():
    """ä¸»å‡½æ•°"""
    parser = argparse.ArgumentParser(description='MiniCRM ä»£ç è´¨é‡æ£€æŸ¥å™¨')
    parser.add_argument('files', nargs='+', help='è¦æ£€æŸ¥çš„Pythonæ–‡ä»¶')
    parser.add_argument('--config', help='é…ç½®æ–‡ä»¶è·¯å¾„')
    parser.add_argument(
        '--format', choices=['json', 'text'], default='json', help='è¾“å‡ºæ ¼å¼')
    parser.add_argument('--output', help='è¾“å‡ºæ–‡ä»¶è·¯å¾„')

    args = parser.parse_args()

    # åŠ è½½é…ç½®
    config = {
        'check_pep8': True,
        'check_type_hints': True,
        'check_docstrings': True,
        'check_imports': True,
        'max_line_length': 88
    }

    if args.config and Path(args.config).exists():
        with open(args.config, 'r', encoding='utf-8') as f:
            config.update(json.load(f))

    # æ‰§è¡Œæ£€æŸ¥
    checker = CodeQualityChecker(config)
    all_issues = []

    for file_path in args.files:
        path = Path(file_path)
        if path.exists() and path.suffix == '.py':
            issues = checker.check_file(path)
            all_issues.extend(issues)

    # ç”ŸæˆæŠ¥å‘Š
    report = generate_report(all_issues, args.format)

    if args.output:
        with open(args.output, 'w', encoding='utf-8') as f:
            f.write(report)
        print(f"æŠ¥å‘Šå·²ä¿å­˜åˆ°: {args.output}")
    else:
        print(report)

    # è¿”å›é€‚å½“çš„é€€å‡ºç 
    error_count = len([i for i in all_issues if i.severity == 'error'])
    sys.exit(1 if error_count > 0 else 0)


if __name__ == '__main__':
    main()
