"""
MiniCRM æ€§èƒ½ä¼˜åŒ–ä½¿ç”¨ç¤ºä¾‹
æ¼”ç¤ºå¦‚ä½•åœ¨å®é™…ä»£ç ä¸­ä½¿ç”¨æ€§èƒ½ä¼˜åŒ–å·¥å…·
"""

import random
import time
from typing import Any

from src.minicrm.config.performance_config import current_config

# å¯¼å…¥æ€§èƒ½ä¼˜åŒ–æ¨¡å—
from src.minicrm.core.performance import (
    PerformanceTracker,
    SmartCache,
    memory_context,
    performance_monitor,
)


# ç¤ºä¾‹1: ä½¿ç”¨æ€§èƒ½ç›‘æ§è£…é¥°å™¨
@performance_monitor("customer_data_processing")
def process_customer_data(customers: list[dict[str, Any]]) -> list[dict[str, Any]]:
    """å¤„ç†å®¢æˆ·æ•°æ®çš„ç¤ºä¾‹å‡½æ•°"""
    processed = []

    for customer in customers:
        # æ¨¡æ‹Ÿæ•°æ®å¤„ç†
        processed_customer = {
            "id": customer["id"],
            "name": customer["name"].upper(),
            "email": customer["email"].lower(),
            "score": calculate_customer_score(customer),
        }
        processed.append(processed_customer)

        # æ¨¡æ‹Ÿä¸€äº›å¤„ç†æ—¶é—´
        time.sleep(0.001)

    return processed


def calculate_customer_score(customer: dict[str, Any]) -> float:
    """è®¡ç®—å®¢æˆ·è¯„åˆ†"""
    # æ¨¡æ‹Ÿå¤æ‚è®¡ç®—
    base_score = random.uniform(0.5, 1.0)

    # æ ¹æ®å®¢æˆ·æ•°æ®è°ƒæ•´è¯„åˆ†
    if customer.get("email"):
        base_score += 0.1
    if customer.get("phone"):
        base_score += 0.1
    if customer.get("company"):
        base_score += 0.2

    return min(base_score, 1.0)


# ç¤ºä¾‹2: ä½¿ç”¨æ™ºèƒ½ç¼“å­˜
class CustomerService:
    """å®¢æˆ·æœåŠ¡ç±» - æ¼”ç¤ºç¼“å­˜ä½¿ç”¨"""

    def __init__(self):
        self.cache = SmartCache(max_size=100, ttl_seconds=300)
        self.db_call_count = 0  # æ¨¡æ‹Ÿæ•°æ®åº“è°ƒç”¨è®¡æ•°

    def get_customer(self, customer_id: int) -> dict[str, Any]:
        """è·å–å®¢æˆ·ä¿¡æ¯ - å¸¦ç¼“å­˜"""
        cache_key = f"customer_{customer_id}"

        # å°è¯•ä»ç¼“å­˜è·å–
        cached_customer = self.cache.get(cache_key)
        if cached_customer is not None:
            print(f"âœ… ç¼“å­˜å‘½ä¸­: customer_{customer_id}")
            return cached_customer

        # ç¼“å­˜æœªå‘½ä¸­ï¼Œä»"æ•°æ®åº“"è·å–
        print(f"ğŸ” ç¼“å­˜æœªå‘½ä¸­ï¼ŒæŸ¥è¯¢æ•°æ®åº“: customer_{customer_id}")
        customer = self._fetch_from_database(customer_id)

        # å­˜å…¥ç¼“å­˜
        self.cache.set(cache_key, customer)

        return customer

    def _fetch_from_database(self, customer_id: int) -> dict[str, Any]:
        """æ¨¡æ‹Ÿæ•°æ®åº“æŸ¥è¯¢"""
        self.db_call_count += 1

        # æ¨¡æ‹Ÿæ•°æ®åº“æŸ¥è¯¢å»¶è¿Ÿ
        time.sleep(0.1)

        return {
            "id": customer_id,
            "name": f"Customer {customer_id}",
            "email": f"customer{customer_id}@example.com",
            "phone": f"138{customer_id:08d}",
            "company": f"Company {customer_id}",
        }

    def get_cache_stats(self) -> dict[str, Any]:
        """è·å–ç¼“å­˜ç»Ÿè®¡"""
        return self.cache.get_stats()


# ç¤ºä¾‹3: ä½¿ç”¨å†…å­˜ä¸Šä¸‹æ–‡ç®¡ç†å™¨
def process_large_dataset():
    """å¤„ç†å¤§æ•°æ®é›†çš„ç¤ºä¾‹"""

    with memory_context("å¤§æ•°æ®é›†å¤„ç†") as memory_manager:
        # ç”Ÿæˆå¤§é‡æ•°æ®
        print("ç”Ÿæˆæµ‹è¯•æ•°æ®...")
        large_dataset = []

        for i in range(50000):
            large_dataset.append(
                {
                    "id": i,
                    "name": f"Item {i}",
                    "value": random.uniform(0, 1000),
                    "category": random.choice(["A", "B", "C", "D"]),
                    "timestamp": time.time(),
                }
            )

        # æ£€æŸ¥å†…å­˜ä½¿ç”¨
        memory_status = memory_manager.check_memory_status()
        print(
            f"æ•°æ®ç”Ÿæˆåå†…å­˜çŠ¶æ€: {memory_status['status']} ({memory_status['current_mb']:.1f}MB)"
        )

        # å¤„ç†æ•°æ®
        print("å¤„ç†æ•°æ®...")
        processed_data = []

        for item in large_dataset:
            if item["value"] > 500:  # åªå¤„ç†å€¼å¤§äº500çš„é¡¹
                processed_item = {
                    "id": item["id"],
                    "name": item["name"],
                    "high_value": True,
                    "processed_at": time.time(),
                }
                processed_data.append(processed_item)

        print(f"å¤„ç†å®Œæˆï¼Œç­›é€‰å‡º {len(processed_data)} ä¸ªé«˜ä»·å€¼é¡¹ç›®")

        # å¦‚æœå†…å­˜ä½¿ç”¨è¿‡é«˜ï¼Œå¼ºåˆ¶åƒåœ¾å›æ”¶
        if memory_status["status"] in ["warning", "critical"]:
            print("æ‰§è¡Œåƒåœ¾å›æ”¶...")
            gc_result = memory_manager.force_garbage_collection()
            print(f"åƒåœ¾å›æ”¶å®Œæˆï¼Œé‡Šæ”¾äº† {gc_result['memory_freed_mb']:.1f}MB å†…å­˜")


# ç¤ºä¾‹4: æ‰¹é‡æ•°æ®åº“æ“ä½œä¼˜åŒ–
class OptimizedDataAccess:
    """ä¼˜åŒ–çš„æ•°æ®è®¿é—®ç±»"""

    def __init__(self):
        self.batch_size = current_config.DB_BATCH_SIZE
        self.operation_count = 0

    def batch_insert_customers(self, customers: list[dict[str, Any]]) -> None:
        """æ‰¹é‡æ’å…¥å®¢æˆ·æ•°æ®"""

        with memory_context("æ‰¹é‡æ’å…¥å®¢æˆ·") as memory_manager:
            print(f"å¼€å§‹æ‰¹é‡æ’å…¥ {len(customers)} ä¸ªå®¢æˆ·ï¼Œæ‰¹é‡å¤§å°: {self.batch_size}")

            # åˆ†æ‰¹å¤„ç†
            for i in range(0, len(customers), self.batch_size):
                batch = customers[i : i + self.batch_size]
                self._insert_batch(batch)

                # æ¯å¤„ç†1000æ¡è®°å½•æ£€æŸ¥ä¸€æ¬¡å†…å­˜
                if (i + self.batch_size) % 1000 == 0:
                    memory_status = memory_manager.check_memory_status()
                    if memory_status["status"] == "warning":
                        print(f"âš ï¸ å†…å­˜ä½¿ç”¨è­¦å‘Š: {memory_status['current_mb']:.1f}MB")

                print(
                    f"å·²å¤„ç† {min(i + self.batch_size, len(customers))}/{len(customers)} æ¡è®°å½•"
                )

    @performance_monitor("database_batch_insert")
    def _insert_batch(self, batch: list[dict[str, Any]]) -> None:
        """æ’å…¥ä¸€æ‰¹æ•°æ®"""
        # æ¨¡æ‹Ÿæ•°æ®åº“æ‰¹é‡æ’å…¥
        self.operation_count += 1
        time.sleep(0.01 * len(batch))  # æ¨¡æ‹Ÿæ•°æ®åº“æ“ä½œæ—¶é—´

        print(f"  æ‰¹æ¬¡ {self.operation_count}: æ’å…¥ {len(batch)} æ¡è®°å½•")


# ç¤ºä¾‹5: æ€§èƒ½åˆ†æå’ŒæŠ¥å‘Š
def performance_analysis_example():
    """æ€§èƒ½åˆ†æç¤ºä¾‹"""

    print("=== æ€§èƒ½åˆ†æç¤ºä¾‹ ===\n")

    # åˆ›å»ºæœåŠ¡å®ä¾‹
    customer_service = CustomerService()
    data_access = OptimizedDataAccess()

    # 1. æµ‹è¯•ç¼“å­˜æ€§èƒ½
    print("1. æµ‹è¯•ç¼“å­˜æ€§èƒ½")
    print("-" * 30)

    # ç¬¬ä¸€æ¬¡è®¿é—®ï¼ˆç¼“å­˜æœªå‘½ä¸­ï¼‰
    start_time = time.time()
    customer1 = customer_service.get_customer(1)
    first_access_time = time.time() - start_time

    # ç¬¬äºŒæ¬¡è®¿é—®ï¼ˆç¼“å­˜å‘½ä¸­ï¼‰
    start_time = time.time()
    customer1_cached = customer_service.get_customer(1)
    second_access_time = time.time() - start_time

    print(f"é¦–æ¬¡è®¿é—®æ—¶é—´: {first_access_time:.4f}ç§’")
    print(f"ç¼“å­˜è®¿é—®æ—¶é—´: {second_access_time:.4f}ç§’")
    print(f"æ€§èƒ½æå‡: {first_access_time / second_access_time:.1f}å€")

    # æ˜¾ç¤ºç¼“å­˜ç»Ÿè®¡
    cache_stats = customer_service.get_cache_stats()
    print(f"ç¼“å­˜ç»Ÿè®¡: {cache_stats}")

    print()

    # 2. æµ‹è¯•å¤§æ•°æ®å¤„ç†
    print("2. æµ‹è¯•å¤§æ•°æ®å¤„ç†")
    print("-" * 30)
    process_large_dataset()

    print()

    # 3. æµ‹è¯•æ‰¹é‡æ“ä½œ
    print("3. æµ‹è¯•æ‰¹é‡æ“ä½œ")
    print("-" * 30)

    # ç”Ÿæˆæµ‹è¯•æ•°æ®
    test_customers = []
    for i in range(500):
        test_customers.append(
            {
                "id": i,
                "name": f"Test Customer {i}",
                "email": f"test{i}@example.com",
            }
        )

    data_access.batch_insert_customers(test_customers)

    print()

    # 4. æ˜¾ç¤ºæ€§èƒ½è·Ÿè¸ªç»“æœ
    print("4. æ€§èƒ½è·Ÿè¸ªç»“æœ")
    print("-" * 30)

    tracker = PerformanceTracker.instance()
    performance_summary = tracker.get_performance_summary()

    for func_name, stats in performance_summary.items():
        print(f"{func_name}:")
        print(f"  å¹³å‡æ‰§è¡Œæ—¶é—´: {stats['avg_time']:.4f}ç§’")
        print(f"  æœ€å¤§æ‰§è¡Œæ—¶é—´: {stats['max_time']:.4f}ç§’")
        print(f"  è°ƒç”¨æ¬¡æ•°: {stats['call_count']}")
        print(f"  å¹³å‡å†…å­˜å˜åŒ–: {stats['avg_memory_delta']:+.2f}MB")
        print()

    # æ˜¾ç¤ºæœ€æ…¢çš„å‡½æ•°
    slowest_functions = tracker.get_slowest_functions(top_n=3)
    print("æœ€æ…¢çš„å‡½æ•°:")
    for i, (func_name, stats) in enumerate(slowest_functions, 1):
        print(f"  {i}. {func_name}: {stats['avg_time']:.4f}ç§’")


if __name__ == "__main__":
    # è¿è¡Œæ€§èƒ½åˆ†æç¤ºä¾‹
    performance_analysis_example()

    print("\n=== æ€§èƒ½ä¼˜åŒ–å»ºè®® ===")
    print("1. ä½¿ç”¨ @performance_monitor è£…é¥°å™¨ç›‘æ§å…³é”®å‡½æ•°")
    print("2. ä½¿ç”¨ SmartCache ç¼“å­˜é¢‘ç¹è®¿é—®çš„æ•°æ®")
    print("3. ä½¿ç”¨ memory_context ç›‘æ§å†…å­˜ä½¿ç”¨")
    print("4. ä½¿ç”¨æ‰¹é‡æ“ä½œå¤„ç†å¤§é‡æ•°æ®")
    print("5. å®šæœŸæ£€æŸ¥ PerformanceTracker çš„ç»Ÿè®¡ä¿¡æ¯")
    print("6. æ ¹æ®é…ç½®è°ƒæ•´æ€§èƒ½å‚æ•°")

    print(f"\nå½“å‰é…ç½®ç¯å¢ƒ: {current_config.__name__}")
    print("å¯é€šè¿‡ç¯å¢ƒå˜é‡ MINICRM_ENV åˆ‡æ¢é…ç½® (development/production)")
